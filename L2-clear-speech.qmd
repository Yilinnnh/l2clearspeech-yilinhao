---
title: "L2 Speakers' Use and Maintenance of Clear Speech in Natural Conversations"
shorttitle: "L2 SPEAKERS' USE AND MAINTENANCE OF CLEAR SPEECH"
author:
  - name: Yilin Hao
    corresponding: true
    email: y2hao@uchicago.edu
    roles:
      - conceptualization
      - writing
      - formal analysis
    affiliations:
      - id: id1
        name: "University of Chicago"
        department: MA Program in the Social Sciences
        address: "1155 E 60th St."
        city: Chicago
        region: IL
        country: USA
        postal-code: 60637

abstract: "This study investigates L2 speakers' use and maintenance of clear speech in natural conversations."

keywords: [L2 speakers, speech production, R programming, ggplot2, data communication]

floatsintext: true
numbered-lines: false
bibliography: [bibliography.bib]
suppress-title-page: false
link-citations: true
draft-date: false
lang: en
language:
  citation-last-author-separator: "and"
  citation-masked-author: "Masked Citation"
  citation-masked-date: "n.d."
  citation-masked-title: "Masked Title"
  email: "Email"
#  title-block-author-note: "Author Note"
#  title-block-correspondence-note: "Correspondence concerning this article should be addressed to"
#  title-block-role-introduction: "Author roles were classified using the Contributor Role Taxonomy (CRediT; https://credit.niso.org/) as follows:"
#  title-impact-statement: "Impact Statement"
  references-meta-analysis: "References marked with an asterisk indicate studies included in the meta-analysis."
format:
  apaquarto-html: default
  apaquarto-docx: default
  apaquarto-typst: 
    keep-typ: true
    list-of-figures: true
    list-of-tables: true
    toc: true
  apaquarto-pdf:
    documentmode: man
    keep-tex: true
    list-of-figures: true
    list-of-tables: true
    fig-width: 2
    fig-height: 2
    out-width: 40%
---

```{r}
#| label: setup
#| include: false
#install packages
#install.packages(conflicted)
#install.packages(papaja)
#install.packages(lme4)
#install.packages(RColorBrewer)
#install.packages(broom)

#load packages
library(conflicted)
library(papaja)
library(dplyr)
library(stringr)
library(lme4)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(stringr)
library(flextable)
library(RColorBrewer)
library(broom)
library(knitr)
library(tidyr)
library(lmerTest)
library(broom.mixed)
library(Matrix)
library(forcats)

conflicts_prefer(dplyr::filter, .quiet = TRUE)
conflicts_prefer(flextable::separate_header, .quiet = TRUE)
conflicts_prefer(flextable::theme_apa, .quiet = TRUE)
conflicts_prefer(lmerTest::lmer, .quiet = TRUE)


set.seed(2222)
```

# Introduction
## Literature Review {#sec-lit-review}
Native English speakers often tend to use clear speech to make their speech more
intelligible in their conversations with people who may have difficulty understanding their
speech, such as non-native speakers. This raises the question: do second language (L2) speakers
of English also use clear speech when communicating with other L2 speakers? This proposed
study may provide insight into L2 speakers’ use of clear speech in natural conversations,
especially whether they will spontaneously adopt this speech style when they are talking to other
L2 speakers and their maintenance of this speech style throughout the conversation.
Literature review
“Clear speech” refers to speakers’ modification of their speech in order to increase the
intelligibility for the listener, which includes various acoustic-phonetic changes like slower
speech and linguistic adaptations like higher frequency words [@tuomainen_speech_2022]. It is
usually used by speakers to accommodate noisy environments, listeners with hearing
impairments, and non-native listeners [@mattys_speech_2012]. In Hazan et al.’s [-@hazan_clear_2018] study of
speech adaptation in conversations with adults with hearing loss, they found some significant
differences in acoustic features between clear speech and normal speech style, which is also
referred to as plain speech, including acoustic cues like articulation rate, mid-frequency range,
and vocal effort which reflected by mean energy within the mid-frequency region.
The benefit of clear speech has been found to be significant when addressing listeners
with impaired hearing [@picheny_speaking_1985] and in noisy environments [@calandruccio_clear-speech_2020]. By
modifying the acoustic cues, clear speech can greatly improve native speakers’ intelligibility
gain [@bradlow_clear_2002]. Although non-native speakers face different challenges in
understanding speech compared to native speakers with hearing impairments or in noisy
environments—difficulty accessing the underlying linguistic code rather than the speech
signal—researchers found that non-native speakers can still benefit from clear speech with
features such as a slower speaking rate and a wider dynamic pitch range [@bradlow_clear_2002]. Recent studies have shown that clear speech has an overall effect in increasing
intelligibility gain regardless of language background, and the benefit difference between l2
speakers and native speakers is not significant [@jung_acoustic_2023]. In addition, L2 speakers
with higher fluency in English demonstrate a clear speech benefit that is more comparable to that
of native speakers. [@smiljanic_bidirectional_2011].
Previous research has shown that besides perceptually benefiting from clear speech,
fluent L2 speakers also exhibit the ability to produce effective acoustic-phonetic modifications in their speech and achieve the effect of clear speech [@kato_perceptual_2022]. Although the
extent of acoustic modification in their speech differs from that of native speakers, L2 speakers
are still able to successfully use clear speech [@jung_acoustic_2023]. By analyzing L2 speakers’ acoustic characteristics while reading given texts in clear and plain speech styles, @jung_acoustic_2023 found that L2 speakers also demonstrated the same clear speech features as native speakers. In other words, L2 speakers exhibited their ability to employ clear speech when they were prompted to do so.

## Present Study {#sec-present-study}
While the prior studies examined the effectiveness of L2 speakers’ clear speech and the perceptual benefit of clear speech for L2 speakers using artificial methods where there’s no actual conversation, there are few studies that examined L2 speakers’ use of clear speech in natural conversations [@smiljanic_bidirectional_2011; @bradlow_clear_2002]. Previous studies have illustrated that native speakers’ clear speech exhibits greater hyperarticulation under artificial methods, where participants are instructed to read texts in a clear speech style, compared to their clear speech produced in natural conversations [@hazan_acoustic-phonetic_2011]. Therefore, in natural conversations, L2 speakers' use of clear speech and its effectiveness may also differ from their performance in artificial contexts. The present study aims to explore whether L2 speakers will spontaneously use clear speech while talking to someone who may have difficulty understanding them— in this study, other non-native speakers— and whether they maintain this use throughout the conversation.
Specifically, the present study aims to answer the following questions: whether L2 speakers will show clear speech characteristics like lower articulation rate, higher F0, and higher mean energy of mid-frequency region [@hazan_clear_2018] in their conversation with other L2 speakers in comparison with their conversation with native speakers, and whether these characteristics persist from the early to the later stages of the conversation. We hypothesize that L2 speakers will use clear speech when interacting with another L2 speaker, indicating their purpose of making their speech more intelligible to non-native listeners [@mattys_speech_2012]. If the hypothesis is true, then native speakers’ speech is expected to show modifications including slower speech rate, greater F0, and higher mean energy in the mid-frequency region during their conversations with L2 speakers compared to their conversations with native speakers [@hazan_clear_2018]. Furthermore, if L2 speakers tend to maintain using clear speech throughout the conversation to meet the intelligibility needs of listeners, they will continue showing these features throughout the speech. Lee and Baese-Berk[-@lee_maintenance_2020] found that native speakers' clear speech became less intelligible in the later portions of a conversation but reset to clear speech at the beginning of the next conversation, which suggests that even though the use of clear speech is oriented by listeners' needs, native speakers do not monitor their listener throughout the conversation. Therefore, it is possible that L2 speakers may use clear speech at an earlier stage of their conversation and become less clear later, which can suggest that the maintenance of clear speech is speaker-driven even though the use of clear speech is mostly listener-driven [@lee_maintenance_2020]. An alternative hypothesis is that they will use plain speech style when they communicate with L2 speakers, thus their acoustic cues and speech signals would not have significant differences when talking to both L2 and native speakers, which can reflect their assumption that their listeners have no problem understanding them.

# Methods
Participants
Participants were students recruited from Northwestern University, including 8 native speakers of English (4 female) and 38 L2 speakers (19 female). L2 speakers were included if they were non-native speakers who could also speak English and demonstrate proficiency in English. These participants had been in the U.S. for no more than 3 years and had achieved TOEFL scores of at least 600 for the paper-based test, 250 for the computer-based test, or 100 for the internet-based test [@van_engen_wildcat_2010].

## Materials  {#sec-materials}
This study will analyze conversations recorded during Diapix tasks, drawn from the Wildcat Corpus [@van_engen_wildcat_2010]. The Diapix task requires two participants to identify differences in a pair of pictures. Each pair of pictures presents the same general scene but with 10 differences: each picture has three items that are missing from the other, and there are four slight differences between the two pictures (“change” items, such as differences in color or other details) [@van_engen_wildcat_2010]. Each participant will be able to see one of a pair of pictures and they are asked to identify all the differences by verbal communication with their partner.

## Procedure  {#sec-procedure}
Participants completed the Diapix task in two groups. One group involves pairs of two L2 speakers, and the second group involves pairs of one L2 speaker with a native English speaker. Participants sat back-to-back in a recording room where they could communicate but could not see each other's pictures. They were instructed to work collaboratively through conversation to identify all the differences in their pictures within 20 minutes and mark them by drawing circles or notes, etc. They wore headsets so their speeches will be recorded separately.

## Data Analysis  {#sec-data-analysis}
Recording of participants’ speech will be transcribed using the phonetic analysis software Praat. The articulation rate will be calculated by the number of syllables produced in speech divided by the total duration of the speech. The mean energy and fundamental frequency will be measured by Praat. The independent variables will be different kinds of participant pairing, including one native speaker and one L2 speaker or two L2 speakers, and different stages of conversation (early or late). We will compare the F0, mean energy, and articulation rate of L2 speakers’ speech between these two groups, either talking to L2 speakers or native speakers. In addition, we will examine how these features vary between the early and late stages of the conversation. The greater F0, mean energy, and slower articulation rate are going to be the indicators of clear speech. The results will be analyzed using R with separate linear mixed-effects models.


```{r}
#| label: data cleaning
#| include: false
data_cleaning <- function(speaker_group) {
  speaker_group %>%
    setNames(c("subject", "F0", "F0_range", "speech_rate", "vowel_duration",
               "early_F0", "early_F0_range", "early_speech_rate", "early_vowel_duration",
               "late_F0", "late_F0_range", "late_speech_rate", "late_vowel_duration")) %>%
    mutate(subject = str_to_upper(str_trim(subject))) %>%
    mutate(
      F0 = as.numeric(gsub("[^0-9\\.\\-]", "", F0)),
      F0_range = as.numeric(gsub("[^0-9\\.\\-]", "", F0_range)),
      speech_rate = as.numeric(gsub("[^0-9\\.\\-]", "", speech_rate)),
      vowel_duration = as.numeric(gsub("[^0-9\\.\\-]", "", vowel_duration)),
      early_F0 = as.numeric(gsub("[^0-9\\.\\-]", "", early_F0)),
      early_F0_range = as.numeric(gsub("[^0-9\\.\\-]", "", early_F0_range)),
      early_speech_rate = as.numeric(gsub("[^0-9\\.\\-]", "", early_speech_rate)),
      early_vowel_duration = as.numeric(gsub("[^0-9\\.\\-]", "", early_vowel_duration)),
      late_F0 = as.numeric(gsub("[^0-9\\.\\-]", "", late_F0)),
      late_F0_range = as.numeric(gsub("[^0-9\\.\\-]", "", late_F0_range)),
      late_speech_rate = as.numeric(gsub("[^0-9\\.\\-]", "", late_speech_rate)),
      late_vowel_duration = as.numeric(gsub("[^0-9\\.\\-]", "", late_vowel_duration))
    ) %>%
    mutate(
      F0 = round(F0, 2),
      F0_range = round(F0_range, 2),
      speech_rate = round(speech_rate, 2),
      vowel_duration = round(vowel_duration, 2),
      early_F0 = round(early_F0, 2),
      early_F0_range = round(early_F0_range, 2),
      early_speech_rate = round(early_speech_rate, 2),
      early_vowel_duration = round(early_vowel_duration, 2),
      late_F0 = round(late_F0, 2),
      late_F0_range = round(late_F0_range, 2),
      late_speech_rate = round(late_speech_rate, 2),
      late_vowel_duration = round(late_vowel_duration, 2)
    )
}


speaker_group1 <- read.csv("L2-clear-speech-data/N-NN.csv")
speaker_group2 <- read.csv("L2-clear-speech-data/NN1-NN1.csv")
speaker_group3 <- read.csv("L2-clear-speech-data/NN1-NN2.csv")

speaker_group1_clean <- data_cleaning(speaker_group1) %>% mutate(group = "native")
speaker_group2_clean <- data_cleaning(speaker_group2) %>% mutate(group = "L2_same_L1")
speaker_group3_clean <- data_cleaning(speaker_group3) %>% mutate(group = "L2_diff_L1")

data_all <- bind_rows(speaker_group1_clean, speaker_group2_clean, speaker_group3_clean)%>%
  mutate(
    group = fct_relevel(group, "L2_diff_L1", "native", "L2_same_L1")
  )


str(data_all[, c("subject", "group", "F0", "F0_range", "speech_rate", "vowel_duration")])

write_csv(data_all, "L2-clear-speech-data/cleaned_data.csv")

```

```{r}
#| label: data-analysis-different-groups
#| include: false

data_long <- data_all %>%
  pivot_longer(
    cols = c(early_F0, late_F0, early_F0_range, late_F0_range, 
             early_speech_rate, late_speech_rate, early_vowel_duration, late_vowel_duration),
    names_to = c("time", "measure"),
    names_pattern = "^(early|late)_(F0(?:_range)?|speech_rate|vowel_duration)$",
    values_to = "value"
  )

extract_lmer_results <- function(model) {
  tidy_model <- broom.mixed::tidy(model, effects = "fixed")
  results <- tidy_model %>%
    mutate(
      beta = round(estimate, 2),
      se = round(std.error, 2),
      t_value = round(statistic, 2),
      p_value = ifelse(p.value < 0.001, "p < .001", paste0("p = ", round(p.value, 4)))
    )
  return(results)
}

mixed_models <- list()
mixed_results <- list()

measures <- c("F0", "F0_range", "speech_rate", "vowel_duration")

for (m in measures) {
  cat("\n", m, ":\n")
  data_m <- data_long %>% 
    filter(measure == m) %>%
    mutate(
      group = factor(group, levels = c("native", "L2_diff_L1", "L2_same_L1")),
      time = factor(time, levels = c("early", "late"))
    )
  
  model_m <- lmer(value ~ time * group + (1 | subject), data = data_m)
  print(summary(model_m))
  
  mixed_models[[m]] <- model_m
  mixed_results[[m]] <- extract_lmer_results(model_m)
}
```

```{r}
#| label: data-analysis-earlyvslate
#| include: false
data_native_vs_l2diff <- data_long %>%
  filter(group %in% c("native", "L2_diff_L1")) %>%
  mutate(
    group = factor(group, levels = c("L2_diff_L1", "native")),
    time = factor(time, levels = c("early", "late"))
  )

lmm_native_vs_l2diff_models <- list()
lmm_native_vs_l2diff_results <- list()

for (m in measures) {
  cat("\n", m, " (Native vs L2_diff_L1):\n")
  
  data_m <- data_native_vs_l2diff %>%
    filter(measure == m)
  
  model_m <- lmer(value ~ time * group + (1 | subject), data = data_m)
  print(summary(model_m))
  
  lmm_native_vs_l2diff_models[[m]] <- model_m
  lmm_native_vs_l2diff_results[[m]] <- extract_lmer_results(model_m)
}

```


```{r}
#| label: tbl-earlydata
#| tbl-cap: "F0, F0 Range, Speech Rate, and Vowel Duration by Conversation Partner"
#| apa-note: "F0 (Hz), F0 Range (Hz), Speech Rate (syllables per second), Vowel Duration (s)"
#| echo: false
data_general_summary <- data_all %>%
  group_by(group) %>%
  summarise(
    F0 = mean(early_F0, na.rm = TRUE),
    `F0 range` = mean(early_F0_range, na.rm = TRUE),
    `Speech Rate` = mean(early_speech_rate, na.rm = TRUE),
    `Vowel Duration` = mean(early_vowel_duration, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  mutate(group = recode(group,
    native = "Native Speaker",
    L2_same_L1 = "L2 Speaker with Same L1",
    L2_diff_L1 = "L2 Speaker with Different L1"
  ))
  
data_general_summary %>%
  rename("Conversation Partner" = group) %>%
  flextable() %>%
  autofit() %>%
  flextable::width(j = 1, width = 2) %>%
  flextable::width(j = 2:5, width = 1) %>%
  flextable::fontsize(size = 9) %>%
  flextable::set_table_properties(width = 0.6) %>%
  theme_apa()
```

```{r}
#| label: fig-f0-boxplot
#| fig-cap: "F0 by Conversation Partner"
#| apa-note: "F0 (Hz) for each group."
#| fig-width: 6
#| fig-height: 4
#| echo: false
data_f0_plot <- data_all %>%
  select(subject, group, early_F0, late_F0) %>%
  pivot_longer(
    cols = c(early_F0, late_F0),
    names_to = "time",
    values_to = "F0_time"
  ) %>%
  mutate(
    time = recode(time, early_F0 = "Early", late_F0 = "Late"),
    group = recode(group,
                   native = "Native Speaker",
                   L2_same_L1 = "L2 Speaker with Same L1",
                   L2_diff_L1 = "L2 Speaker with Different L1"),
    group = fct_reorder(group, F0_time, .fun = mean, na.rm = TRUE)
  )

my_colors <- c(
  "Native Speaker" = "#FCCB9B",
  "L2 Speaker with Same L1" = "#B2D2FF",
  "L2 Speaker with Different L1" = "#D1B2FF"
)

ggplot(data_f0_plot, aes(x = group, y = F0_time, fill = group)) +
  geom_boxplot(
    width = 0.4, 
    outlier.shape = 21, 
    outlier.size = 2, 
    outlier.stroke = 0.5, 
    outlier.fill = "white", 
    coef = Inf
  ) +
  scale_fill_manual(values = my_colors) +
  labs(
    x = "Conversation Partner", 
    y = "F0 (Hz)"
  ) +
  facet_wrap(~ time, nrow = 1) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 15, hjust = 0.5),
    legend.position = "none"
  )

```

```{r}
#| label: fig-f0range-boxplot
#| fig-cap: "F0 Range by Conversation Partner"
#| apa-note: "F0 Range (Hz) for each group."
#| fig-width: 6
#| fig-height: 4
#| echo: false
data_f0range_plot <- data_all %>%
  select(subject, group, early_F0_range, late_F0_range) %>%
  pivot_longer(
    cols = c(early_F0_range, late_F0_range),
    names_to = "time",
    values_to = "F0_range_time",
    names_repair = "minimal"
  ) %>%
  mutate(
    time = recode(time, early_F0_range = "Early", late_F0_range = "Late"),
    group = recode(group,
                   native = "Native Speaker",
                   L2_same_L1 = "L2 Speaker with Same L1",
                   L2_diff_L1 = "L2 Speaker with Different L1"),
    group = fct_reorder(group, F0_range_time, .fun = mean, na.rm = TRUE)
  )

ggplot(data_f0range_plot, aes(x = group, y = F0_range_time, fill = group)) +
  geom_boxplot(
    width = 0.4,
    outlier.shape = 21,
    outlier.size = 2,
    outlier.stroke = 0.5,
    outlier.fill = "white",
    coef = Inf
  ) +
  scale_fill_manual(values = my_colors) +
  labs(
    x = "Conversation Partner",
    y = "F0 Range (Hz)"
  ) +
  facet_grid(. ~ time) +
  theme_minimal(base_size = 12) +
  theme(
    axis.text.x = element_text(angle = 15, hjust = 0.5),
    legend.position = "none"
  )

```
```{r}
#| label: fig-f0range-violin-plot
#| fig-cap: "F0 Range by Conversation Stage"
#| apa-note: "F0 Range (Hz)."
#| fig-width: 4
#| fig-height: 3
#| echo: false
# Violin plot for L2_diff_L1 group: comparing Early and Late stages (F0)
data_l2diff_violin <- data_long %>%
  filter(group == "L2_diff_L1", measure == "F0_range") %>%
  mutate(
    time = recode(time, early = "Early", late = "Late")
  )

ggplot(data_l2diff_violin, aes(x = time, y = value, fill = time)) +
  geom_violin(trim = FALSE, alpha = 0.7) +
  geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) +
  scale_fill_manual(values = c("Early" = "#D1B2FF", "Late" = "#D1B2FF")) +
  labs(
    x = "Conversation Stage",
    y = "F0 (Hz)"
  ) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "none")
```

```{r}
#| label: gender-difference-analysis
#| include: false
data_f0_gender <- data_all %>%
  filter(group == "L2_diff_L1") %>%
  mutate(
    gender = ifelse(grepl("f", subject, ignore.case = TRUE), "Female", "Male")
  )

overall_mean_F0 <- mean(data_f0_gender$early_F0, na.rm = TRUE)

f0_summary <- data_f0_gender %>%
  group_by(gender) %>%
  summarise(
    mean_F0 = mean(early_F0, na.rm = TRUE),
    sd_F0 = sd(early_F0, na.rm = TRUE),
    min_F0 = min(early_F0, na.rm = TRUE),
    max_F0 = max(early_F0, na.rm = TRUE),
    range_F0 = max(early_F0, na.rm = TRUE) - min(early_F0, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  mutate(
    above_overall_mean = mean_F0 > overall_mean_F0
  )

print(f0_summary)
cat("Overall Mean F0:", overall_mean_F0, "\n")
```

```{r}
#| label: fig-f0-gender-difference-l2diffl1-group
#| fig-cap: "F0 Comparison by Gender in L2 Speakers"
#| apa-note: "F0 (Hz)."
#| fig-width: 4
#| fig-height: 3
#| echo: false
ggplot(data_f0_gender, aes(x = gender, y = early_F0, fill = gender)) +
  geom_boxplot(outlier.shape = 21, outlier.fill = "white") +
  geom_hline(yintercept = overall_mean_F0, linetype = "dashed", color = "black") +
  geom_text(data = f0_summary, aes(x = gender, y = mean_F0, label = ifelse(above_overall_mean, "Above Mean", "Below Mean")),
            vjust = -1, size = 3, color = "black") +
  scale_fill_manual(values = c("Female" = "#FF9999", "Male" = "#99CCFF")) +
  labs(
    x = "Gender",
    y = "Early F0 (Hz)",
    fill = "Gender"
  ) +
  theme_minimal(base_size = 14)

```

# Results
The linear mixed-effects regression model reveals that L2 speakers' F0 range is larger when their conversation partner is an L2 speaker with a different L1 with them (M = `r data_general_summary[["F0 range"]][data_general_summary$group == "L2 Speaker with Different L1"]`) compared to when the conversation partner is native speaker (M = `r data_general_summary[["F0 range"]][data_general_summary$group == "Native Speaker"]`) (β = `r mixed_results[['F0_range']]$beta[mixed_results[['F0_range']]$term == "groupL2_diff_L1"]`, SE = `r mixed_results[['F0_range']]$se[mixed_results[['F0_range']]$term == "groupL2_diff_L1"]`, `r mixed_results[['F0_range']]$p_value[mixed_results[['F0_range']]$term == "groupL2_diff_L1"]`). In addition, there is a tendency for L2 speakers' F0 to be greater when they speak with an L2 speaker with a different L1 (M = `r data_general_summary$F0[data_general_summary$group == "L2 Speaker with Different L1"]`) than when speaking with a native speaker (M = `r data_general_summary$F0[data_general_summary$group == "Native Speaker"]`), but the difference is not significant (β = `r mixed_results[['F0']]$beta[mixed_results[['F0']]$term == "groupL2_diff_L1"]`, SE = `r mixed_results[['F0']]$se[mixed_results[['F0']]$term == "groupL2_diff_L1"]`, `r mixed_results[['F0']]$p_value[mixed_results[['F0']]$term == "groupL2_diff_L1"]`). 
There is no significant difference in speech rate between the L2 listener (M = `r data_general_summary[["Speech Rate"]][data_general_summary$group == "L2 Speaker with Different L1"]`) and native listener conditions (M = `r data_general_summary[["Speech Rate"]][data_general_summary$group == "Native Speaker"]`) (β = `r mixed_results[['speech_rate']]$beta[mixed_results[['speech_rate']]$term == "groupL2_diff_L1"]`, SE = `r mixed_results[['speech_rate']]$se[mixed_results[['speech_rate']]$term == "groupL2_diff_L1"]`, `r mixed_results[['speech_rate']]$p_value[mixed_results[['speech_rate']]$term == "groupL2_diff_L1"]`). Similarly, vowel duration does not differ significantly between the L2 listener (M = `r data_general_summary[["Vowel Duration"]][data_general_summary$group == "L2 Speaker with Different L1"]`) and native listener conditions (M = `r data_general_summary[["Vowel Duration"]][data_general_summary$group == "Native Speaker"]`) (β = `r mixed_results[['vowel_duration']]$beta[mixed_results[['vowel_duration']]$term == "groupL2_diff_L1"]`, SE = `r mixed_results[['vowel_duration']]$se[mixed_results[['vowel_duration']]$term == "groupL2_diff_L1"]`, `r mixed_results[['vowel_duration']]$p_value[mixed_results[['vowel_duration']]$term == "groupL2_diff_L1"]`). Further, there is no significant difference in F0 or F0 range between early and late portion of the conversation as shown in @fig-f0-boxplot, @fig-f0range-boxplot, and @fig-f0range-violin-plot.

# Discussion
This study examines L2 speakers' use of **clear speech**[^1] in natural conversations. Specifically, we investigate whether L2 speakers employ clear speech when communicating with another L2 speaker who has a different L1. The results indicate that their F0 range is significantly larger when speaking to another L2 speaker compared to a native speaker. Although the mean difference in F0 between these two groups is large, it does not reach statistical significance, possibly due to the high variance in F0 between female and male speakers in our dataset[^2]. As shown in @fig-f0-gender-difference-l2diffl1-group, female and male speakers inherently exhibit different F0 values due to physiological differences. However, the significant increase in F0 range suggests that L2 speakers actively hyperarticulate their speech.

There is no significant difference in speech rate and vowel duration, which may be because L2 speakers generally speak at a slower rate[^3]. Since they do not expect their listeners to have trouble understanding them, they may not adjust their speech in these ways. Additionally, the lack of significant differences between the early and late portions of speech suggests that L2 speakers consistently monitor their speech throughout the conversation.


[^1]: **Clear speech** refers to speech modifications that enhance intelligibility, including:  
&nbsp;&nbsp;&nbsp;&nbsp; - Greater F0  
&nbsp;&nbsp;&nbsp;&nbsp; - Greater F0 range  
&nbsp;&nbsp;&nbsp;&nbsp; - Slower articulation rate  
&nbsp;&nbsp;&nbsp;&nbsp; - Longer vowel duration 

[^2]: Female speakers generally have a higher F0 than male speakers.  

[^3]: The participants’ speech rate is approximately 3 syllables per second, which is considerably slower than the typical speech rate of native speakers.



\clearpage

# References

:::{#refs}
:::
